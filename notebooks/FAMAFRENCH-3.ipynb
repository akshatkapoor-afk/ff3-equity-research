{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akWraY7Wwj_Y"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"No supported index is available.\", module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"A date index has been provided\", module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Only PeriodIndexes, DatetimeIndexes with a frequency set\", module=\"statsmodels\")\n",
        "!pip -q install yfinance pandas numpy matplotlib seaborn statsmodels arch\n",
        "\n",
        "import warnings, logging\n",
        "from statsmodels.tools.sm_exceptions import ValueWarning as SMValueWarning\n",
        "\n",
        "# Silence statsmodels AR indexing warnings\n",
        "warnings.filterwarnings(\"ignore\", category=SMValueWarning)  # statsmodels' own ValueWarning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning,   module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"No supported index is available.\", module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"A date index has been provided\",   module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Only PeriodIndexes, DatetimeIndexes with a frequency set\", module=\"statsmodels\")\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"date_parser\", module=\"pandas\")\n",
        "\n",
        "import warnings\n",
        "from statsmodels.tools.sm_exceptions import ValueWarning as SMValueWarning\n",
        "warnings.filterwarnings(\"ignore\", category=SMValueWarning, module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning,   module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"No supported index is available.\", module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"A date index has been provided\",   module=\"statsmodels\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Only PeriodIndexes, DatetimeIndexes with a frequency set\", module=\"statsmodels\")\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "sns.set_context(\"talk\")\n",
        "tickers = [\"AAPL\",\"MSFT\",\"AMZN\",\"META\",\"NVDA\",\"XOM\",\"JPM\",\"KO\",\"JNJ\",\"TSLA\"]\n",
        "start = \"2019-01-01\"   # covers multiple regimes\n",
        "end   = None           # up to latest available\n",
        "\n",
        "data = yf.download(tickers, start=start, end=end)\n",
        "print(data.columns)\n",
        "prices = data[\"Close\"]\n",
        "display(prices.head())\n",
        "\n",
        "prices.head()                 # first 5 rows\n",
        "prices.tail()                 # last 5 rows\n",
        "prices.shape                  # (rows, columns)\n",
        "prices.isna().sum()\n",
        "prices.index.min(), prices.index.max()\n",
        "prices.dtypes.head()\n",
        "\n",
        "# simple daily returns: (P_t / P_{t-1}) - 1\n",
        "rets = prices.pct_change().dropna()\n",
        "\n",
        "# quick peek & sanity stats (returns are small numbers like -0.02 .. +0.02)\n",
        "display(rets.head())\n",
        "rets.describe().T.iloc[:, :4]\n",
        "\n",
        "!pip -q install pandas-datareader\n",
        "\n",
        "import pandas as pd\n",
        "from pandas_datareader import data as web\n",
        "\n",
        "# This fetches the official daily FF3 dataset directly\n",
        "ff = web.DataReader('F-F_Research_Data_Factors_Daily', 'famafrench')\n",
        "\n",
        "# ff[0] is the daily table with columns: 'Mkt-RF','SMB','HML','RF' in PERCENT units\n",
        "ff3 = ff[0].copy()\n",
        "\n",
        "# Making sure the index is datetime (it already is; this keeps it explicit)\n",
        "ff3.index = pd.to_datetime(ff3.index)\n",
        "\n",
        "# Converting percent → decimals to match stock returns\n",
        "ff3 = ff3 / 100.0\n",
        "\n",
        "#clean column names just in case\n",
        "ff3.columns = [c.strip() for c in ff3.columns]\n",
        "\n",
        "ff3.head()\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.6f}'.format\n",
        "\n",
        "ff3[['RF']].loc['2019':].head(10)      # inspect early rows\n",
        "ff3['RF'].describe()                   # min / max\n",
        "(float((ff3['RF']==0).mean()), 'fraction of zero RF days')  # share of zeros\n",
        "ff3['RF'].value_counts().head(10)      # common values\n",
        "\n",
        "\n",
        "data = rets.join(ff3[['Mkt-RF','SMB','HML','RF']], how='inner').dropna()\n",
        "data.shape, data.head()\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "t = \"AAPL\"\n",
        "y = data[t] - data[\"RF\"]\n",
        "X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]])\n",
        "\n",
        "m_ols = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "m_hac = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":5})  # ~1 trading week\n",
        "\n",
        "print(m_hac.summary())\n",
        "\n",
        "\n",
        "def ff3_stats_hac(df, ticker, maxlags=5):\n",
        "    y = df[ticker] - df[\"RF\"]\n",
        "    X = sm.add_constant(df[[\"Mkt-RF\",\"SMB\",\"HML\"]])\n",
        "    m = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":maxlags})\n",
        "    return {\n",
        "        \"alpha_daily\": m.params[\"const\"],\n",
        "        \"alpha_annual\": m.params[\"const\"] * 252,\n",
        "        \"beta_mkt\": m.params[\"Mkt-RF\"],\n",
        "        \"beta_smb\": m.params[\"SMB\"],\n",
        "        \"beta_hml\": m.params[\"HML\"],\n",
        "        \"t_alpha\": m.tvalues[\"const\"],\n",
        "        \"t_mkt\": m.tvalues[\"Mkt-RF\"],\n",
        "        \"t_smb\": m.tvalues[\"SMB\"],\n",
        "        \"t_hml\": m.tvalues[\"HML\"],\n",
        "        \"p_alpha\": m.pvalues[\"const\"],\n",
        "        \"r2\": m.rsquared,\n",
        "        \"n\": int(m.nobs),\n",
        "    }, m\n",
        "\n",
        "rows, models = [], {}\n",
        "for tkr in rets.columns:\n",
        "    r, mdl = ff3_stats_hac(data, tkr)\n",
        "    r[\"ticker\"] = tkr\n",
        "    rows.append(r); models[tkr] = mdl\n",
        "\n",
        "results = pd.DataFrame(rows).set_index(\"ticker\").sort_index()\n",
        "results.round(4)\n",
        "\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(results[[\"beta_mkt\",\"beta_smb\",\"beta_hml\"]], annot=True, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Fama–French 3-Factor Loadings\"); plt.xlabel(\"Factor\"); plt.ylabel(\"Ticker\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "results[\"alpha_annual\"].sort_values().plot(kind=\"barh\", figsize=(10,5), color=\"steelblue\")\n",
        "plt.axvline(0, color=\"k\", lw=1); plt.title(\"Annualized Alpha (HAC SEs)\")\n",
        "plt.xlabel(\"Alpha per year\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "sig_alpha = results.index[results[\"p_alpha\"] < 0.05].tolist()\n",
        "print(\"Significant alpha @5% (HAC):\", sig_alpha if sig_alpha else \"None\")\n",
        "\n",
        "t = \"NVDA\"\n",
        "y = data[t] - data[\"RF\"]\n",
        "X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]])\n",
        "pred = models[t].predict(X)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(y.index, y,   label=f\"{t} Excess Return\", alpha=0.6)\n",
        "plt.plot(y.index, pred,label=\"FF3 Predicted\", alpha=0.8)\n",
        "plt.title(f\"{t}: Actual vs FF3 Predicted (daily excess returns)\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def describe(t, res):\n",
        "    bM, bS, bH = res.loc[t,[\"beta_mkt\",\"beta_smb\",\"beta_hml\"]]\n",
        "    aA, pA = res.loc[t,[\"alpha_annual\",\"p_alpha\"]]\n",
        "    r2, n  = res.loc[t,[\"r2\",\"n\"]]\n",
        "    tiltM = \"high beta\" if bM>1.2 else \"low beta\" if bM<0.8 else \"market-like beta\"\n",
        "    tiltS = \"small-cap tilt\" if bS>0 else \"large-cap tilt\"\n",
        "    tiltH = \"value tilt\" if bH>0 else \"growth tilt\"\n",
        "    sigA  = \"significant\" if pA<0.05 else \"not significant\"\n",
        "    return f\"{t}: {tiltM}, {tiltS}, {tiltH}; alpha {aA:.2%} ({sigA}); R²={r2:.2f}, N={int(n)}.\"\n",
        "\n",
        "for t in results.index: print(describe(t, results))\n",
        "\n",
        "results.round(6).to_csv(\"ff3_results_hac.csv\")\n",
        "\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "tickers_to_show = [\"NVDA\", \"TSLA\", \"JPM\"]\n",
        "\n",
        "\n",
        "def get_model_for(t):\n",
        "    y = data[t] - data[\"RF\"]\n",
        "    X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]])\n",
        "    try:\n",
        "        m = models[t]\n",
        "    except NameError:\n",
        "        m = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "    except KeyError:\n",
        "        m = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "    return m, y, X\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12,10), sharex=True)\n",
        "for ax, t in zip(axes, tickers_to_show):\n",
        "    m, y, X = get_model_for(t)\n",
        "    pred = m.predict(X)\n",
        "\n",
        "    # main plot: daily excess vs fitted\n",
        "    ax.plot(y.index, y,   label=f\"{t} excess return\", color=\"#555\", alpha=0.55)\n",
        "    ax.plot(y.index, pred, label=\"FF3 fitted\", color=\"#1976d2\", alpha=0.85)\n",
        "\n",
        "    # smoothing overlay\n",
        "    y_r   = y.rolling(20).mean()\n",
        "    pr_r  = pd.Series(pred, index=y.index).rolling(20).mean()\n",
        "    ax.plot(y.index, y_r,  color=\"#000\", lw=1.2, alpha=0.7)\n",
        "    ax.plot(y.index, pr_r, color=\"#0d47a1\", lw=1.2, alpha=0.9)\n",
        "\n",
        "    # quick metrics\n",
        "    rmse = np.sqrt(np.mean((y - pred)**2))\n",
        "    corr = np.corrcoef(y.fillna(0), pd.Series(pred, index=y.index).fillna(0))[0,1]\n",
        "    ax.set_title(f\"{t}: Actual vs FF3 Fitted • R²={m.rsquared:.2f} • RMSE={rmse:.4f} • Corr={corr:.2f}\")\n",
        "    ax.legend(loc=\"upper right\")\n",
        "    ax.set_ylabel(\"Daily excess return\")\n",
        "\n",
        "axes[-1].set_xlabel(\"Date\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# (actual vs fitted)\n",
        "import seaborn as sns\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14,4))\n",
        "for ax, t in zip(axes, tickers_to_show):\n",
        "    m, y, X = get_model_for(t)\n",
        "    pred = m.predict(X)\n",
        "    dfp = pd.DataFrame({\"actual\": y, \"fitted\": pred}).dropna()\n",
        "    sns.regplot(data=dfp, x=\"fitted\", y=\"actual\", ax=ax,\n",
        "                scatter_kws={\"alpha\":0.3, \"s\":8}, line_kws={\"color\":\"crimson\"})\n",
        "    ax.set_title(f\"{t}: scatter (fitted vs actual)\\nCorr={dfp.corr().iloc[0,1]:.2f}\")\n",
        "    ax.set_xlabel(\"FF3 fitted (daily excess)\")\n",
        "    ax.set_ylabel(\"Actual (daily excess)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def scenario_return(ticker, mkt_rf, smb, hml):\n",
        "    b = models[ticker].params  # const, Mkt-RF, SMB, HML\n",
        "    return float(b['const'] + b['Mkt-RF']*mkt_rf + b['SMB']*smb + b['HML']*hml)\n",
        "\n",
        "scenarios = pd.DataFrame([\n",
        "    {\"Scenario\":\"Mkt +2%, SMB 0, HML 0\",      \"Mkt-RF\":0.02, \"SMB\":0.00, \"HML\":0.00},\n",
        "    {\"Scenario\":\"Mkt +1%, SMB +0.3%, HML -0.3%\",\"Mkt-RF\":0.01, \"SMB\":0.003,\"HML\":-0.003},\n",
        "    {\"Scenario\":\"Mkt -1%, SMB -0.3%, HML +0.3%\",\"Mkt-RF\":-0.01,\"SMB\":-0.003,\"HML\":0.003},\n",
        "    {\"Scenario\":\"Flat factors\",\"Mkt-RF\":0.0,\"SMB\":0.0,\"HML\":0.0},\n",
        "])\n",
        "\n",
        "for t in [\"NVDA\",\"TSLA\",\"JPM\"]:\n",
        "    scenarios[t] = scenarios.apply(lambda r: scenario_return(t, r[\"Mkt-RF\"], r[\"SMB\"], r[\"HML\"]), axis=1)\n",
        "\n",
        "scenarios\n",
        "\n",
        "# factor premia (daily means) from the sample window\n",
        "mu_factors = data[[\"Mkt-RF\",\"SMB\",\"HML\"]].mean()\n",
        "rf_daily   = data[\"RF\"].mean()\n",
        "\n",
        "rows = []\n",
        "for t in [\"NVDA\",\"TSLA\",\"JPM\"]:\n",
        "    b = models[t].params\n",
        "    exp_excess_daily = float(b['const'] + b['Mkt-RF']*mu_factors[\"Mkt-RF\"] +\n",
        "                             b['SMB']*mu_factors[\"SMB\"] + b['HML']*mu_factors[\"HML\"])\n",
        "    exp_excess_annual = exp_excess_daily * 252\n",
        "    exp_total_annual  = exp_excess_annual + rf_daily*252\n",
        "    rows.append([t, exp_excess_daily, exp_excess_annual, exp_total_annual])\n",
        "\n",
        "exp_table = pd.DataFrame(rows, columns=[\"Ticker\",\"E[Excess]_daily\",\"E[Excess]_annual\",\"E[Total]_annual\"])\n",
        "exp_table\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "\n",
        "# y_excess and factors aligned\n",
        "def rolling_ff3_forecast(ticker, window=252, use_ar1=True, min_len_ar=30):\n",
        "    \"\"\"\n",
        "    Walk-forward forecast of next-day EXCESS return for `ticker`.\n",
        "    - window: trailing window (trading days) for beta estimation\n",
        "    - use_ar1: True -> AR(1) forecast for factors; False -> naive (use last observed)\n",
        "    - min_len_ar: minimum observations to fit AR(1); otherwise fall back to naive\n",
        "    \"\"\"\n",
        "    y_excess = (data[ticker] - data[\"RF\"]).dropna()\n",
        "    fac = data[[\"Mkt-RF\",\"SMB\",\"HML\"]].loc[y_excess.index]  # same dates as y\n",
        "\n",
        "    preds = pd.Series(index=y_excess.index, dtype=float)\n",
        "\n",
        "    for i in range(window, len(y_excess)-1):\n",
        "        # 1) Estimating betas on trailing window [i-window, i)\n",
        "        Yw = y_excess.iloc[i-window:i]\n",
        "        Xw = sm.add_constant(fac.iloc[i-window:i])\n",
        "        b  = sm.OLS(Yw, Xw).fit().params  # const, Mkt-RF, SMB, HML\n",
        "\n",
        "        # 2) Forecasting factors for day i+1\n",
        "        if use_ar1:\n",
        "            fhat = {}\n",
        "            for col in fac.columns:\n",
        "                series = fac[col].iloc[:i].dropna()\n",
        "                if len(series) >= min_len_ar:\n",
        "                    try:\n",
        "                        ar = AutoReg(series, lags=1, old_names=False).fit()\n",
        "                        fhat[col] = float(ar.forecast(steps=1)[0])  # <-- key change\n",
        "                    except Exception:\n",
        "                        fhat[col] = float(series.iloc[-1])          # fallback\n",
        "                else:\n",
        "                    fhat[col] = float(series.iloc[-1])              # fallback\n",
        "        else:\n",
        "            # naive persistence: next factor = last observed factor\n",
        "            fhat = fac.iloc[i].to_dict()\n",
        "\n",
        "        # 3) next-day prediction\n",
        "        next_idx = y_excess.index[i+1]\n",
        "        preds.loc[next_idx] = (\n",
        "            b['const'] + b['Mkt-RF']*fhat['Mkt-RF'] +\n",
        "            b['SMB']*fhat['SMB'] + b['HML']*fhat['HML']\n",
        "        )\n",
        "\n",
        "    out = pd.DataFrame({\"pred\": preds, \"actual\": y_excess}).dropna()\n",
        "    rmse = float(np.sqrt(np.mean((out['pred']-out['actual'])**2)))\n",
        "    corr = float(out['pred'].corr(out['actual']))\n",
        "    hit  = float((np.sign(out['pred']) == np.sign(out['actual'])).mean())\n",
        "    return out, {\"RMSE\": rmse, \"Corr\": corr, \"HitRate\": hit}\n",
        "targets = [\"NVDA\",\"TSLA\",\"JPM\"]\n",
        "metrics = {}\n",
        "series  = {}\n",
        "\n",
        "for t in targets:\n",
        "    df, m = rolling_ff3_forecast(ticker=t, window=252, use_ar1=True)\n",
        "    metrics[t] = m\n",
        "    series[t]  = df\n",
        "    print(t, m)\n",
        "\n",
        "# actual vs predicted (cumulative to see drift)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14,4), sharey=True)\n",
        "for ax, t in zip(axes, targets):\n",
        "    df = series[t]\n",
        "    cum_pred   = (1 + df['pred']).cumprod() - 1\n",
        "    cum_actual = (1 + df['actual']).cumprod() - 1\n",
        "    ax.plot(cum_actual.index, cum_actual, label=\"Actual (cum excess)\", color=\"#555\")\n",
        "    ax.plot(cum_pred.index,   cum_pred,   label=\"Predicted (cum excess)\", color=\"#1976d2\")\n",
        "    ax.set_title(f\"{t}  •  Corr={metrics[t]['Corr']:.2f} • Hit={metrics[t]['HitRate']:.2f}\")\n",
        "    ax.legend(); ax.grid(alpha=0.2)\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "!pip -q install pandas-datareader\n",
        "from pandas_datareader import data as web\n",
        "import pandas as pd, statsmodels.api as sm\n",
        "\n",
        "# 5 factors (daily, % units) and Momentum\n",
        "ff5 = web.DataReader('F-F_Research_Data_5_Factors_2x3_Daily','famafrench')[0] / 100.0\n",
        "mom = web.DataReader('F-F_Momentum_Factor_Daily','famafrench')[0] / 100.0\n",
        "ff5.index = pd.to_datetime(ff5.index); mom.index = pd.to_datetime(mom.index)\n",
        "\n",
        "# joining toreturns index\n",
        "ffX = ff5.join(mom, how=\"inner\")\n",
        "ffX[\"RF\"] = ff3[\"RF\"]\n",
        "# Align with returns\n",
        "datX = rets.join(ffX, how=\"inner\")\n",
        "\n",
        "def run_model(df, ticker, cols):\n",
        "    X = sm.add_constant(df[cols])\n",
        "    m = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":5})\n",
        "    return m\n",
        "\n",
        "cols_ff3 = [\"Mkt-RF\",\"SMB\",\"HML\"]\n",
        "cols_ff5 = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
        "cols_car4= [\"Mkt-RF\",\"SMB\",\"HML\",\"Mom\"]\n",
        "\n",
        "for t in [\"NVDA\",\"TSLA\",\"JPM\"]:\n",
        "    m3  = run_model(datX, t, cols_ff3)\n",
        "    m5  = run_model(datX, t, cols_ff5)\n",
        "    m4  = run_model(datX, t, cols_car4)\n",
        "    print(f\"\\n{t}: R2 FF3={m3.rsquared:.3f}  FF5={m5.rsquared:.3f}  Carhart4={m4.rsquared:.3f}\")\n",
        "    print(f\" alpha_annual FF3={m3.params['const']*252:.2%}  FF5={m5.params['const']*252:.2%}  Car4={m4.params['const']*252:.2%}\")\n",
        "\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "\n",
        "def rolling_ff3_forecast_clean(ticker, window=252, use_ar1=True, min_len_ar=30):\n",
        "    \"\"\"\n",
        "    True 1-day-ahead forecast:\n",
        "    - betas estimated on trailing `window` days\n",
        "    - next-day factors via AR(1) (fallback = last value)\n",
        "    - prediction written at the next trading date\n",
        "    \"\"\"\n",
        "    y_excess = (data[ticker] - data[\"RF\"]).dropna()\n",
        "    fac = data[[\"Mkt-RF\",\"SMB\",\"HML\"]].loc[y_excess.index]\n",
        "\n",
        "    preds = pd.Series(index=y_excess.index, dtype=float)\n",
        "\n",
        "    for i in range(window, len(y_excess)-1):\n",
        "        # 1) betas from trailing window\n",
        "        Yw = y_excess.iloc[i-window:i]\n",
        "        Xw = sm.add_constant(fac.iloc[i-window:i])\n",
        "        b  = sm.OLS(Yw, Xw).fit().params\n",
        "\n",
        "        # 2) AR(1) forecast for each factor (robust to datetime index)\n",
        "        if use_ar1:\n",
        "            fhat = {}\n",
        "            for col in fac.columns:\n",
        "                series = fac[col].iloc[:i].dropna()\n",
        "                if len(series) >= min_len_ar:\n",
        "                    sr = pd.Series(series.to_numpy())           # RangeIndex\n",
        "                    ar = AutoReg(sr, lags=1, old_names=False).fit()\n",
        "                    fhat[col] = float(ar.forecast(steps=1).iloc[0])\n",
        "                else:\n",
        "                    fhat[col] = float(series.iloc[-1])\n",
        "        else:\n",
        "            fhat = fac.iloc[i].to_dict()                        # persistence\n",
        "\n",
        "        # 3) write prediction at next trading timestamp\n",
        "        next_idx = y_excess.index[i+1]\n",
        "        preds.loc[next_idx] = (\n",
        "            b['const'] + b['Mkt-RF']*fhat['Mkt-RF'] +\n",
        "            b['SMB']*fhat['SMB'] + b['HML']*fhat['HML']\n",
        "        )\n",
        "\n",
        "    out = pd.DataFrame({\"pred\": preds, \"actual\": y_excess}).dropna()\n",
        "    rmse = float(np.sqrt(np.mean((out['pred']-out['actual'])**2)))\n",
        "    corr = float(out['pred'].corr(out['actual']))\n",
        "    hit  = float((np.sign(out['pred']) == np.sign(out['actual'])).mean())\n",
        "    return out, {\"RMSE\": rmse, \"Corr\": corr, \"HitRate\": hit}\n",
        "df_nvda, m_nvda = rolling_ff3_forecast_clean(\"NVDA\")\n",
        "df_tsla, m_tsla = rolling_ff3_forecast_clean(\"TSLA\")\n",
        "df_jpm,  m_jpm  = rolling_ff3_forecast_clean(\"JPM\")\n",
        "\n",
        "def check_oos(df, window=252):\n",
        "    first_actual = df['actual'].index.min()\n",
        "    first_pred   = df['pred'].first_valid_index()\n",
        "    print(\"First actual:\", first_actual)\n",
        "    print(\"First pred:  \", first_pred)\n",
        "    print(\"Pred starts after training window? ->\", first_pred > first_actual)\n",
        "    print(\"Rows actual/pred:\", df['actual'].shape[0], df['pred'].dropna().shape[0])\n",
        "\n",
        "check_oos(df_nvda)\n",
        "check_oos(df_tsla)\n",
        "check_oos(df_jpm)\n",
        "\n",
        "def verify_oos(ticker, df, window=252):\n",
        "    y = (data[ticker] - data['RF']).dropna()\n",
        "    full_start     = y.index.min()\n",
        "    expected_start = y.index[window+1]      # first 1-day-ahead pred date\n",
        "    df_start       = df.index.min()\n",
        "    print(f\"\\n{ticker}\")\n",
        "    print(\"Full series start:        \", full_start)\n",
        "    print(\"Expected first forecast:  \", expected_start)\n",
        "    print(\"DF (actual & pred) start: \", df_start)\n",
        "    print(\"Matches expected?         \", df_start == expected_start)\n",
        "    print(\"Orig obs:\", len(y), \"  Forecast rows:\", len(df))\n",
        "\n",
        "verify_oos(\"NVDA\", df_nvda)\n",
        "verify_oos(\"TSLA\", df_tsla)\n",
        "verify_oos(\"JPM\",  df_jpm)\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "def metrics_row(name, df):\n",
        "    rmse = float(np.sqrt(np.mean((df['pred']-df['actual'])**2)))\n",
        "    corr = float(df['pred'].corr(df['actual']))\n",
        "    hit  = float((np.sign(df['pred']) == np.sign(df['actual'])).mean())\n",
        "    return pd.Series({'RMSE': rmse, 'Corr': corr, 'HitRate': hit})\n",
        "\n",
        "metrics = pd.DataFrame({\n",
        "    'NVDA': metrics_row('NVDA', df_nvda),\n",
        "    'TSLA': metrics_row('TSLA', df_tsla),\n",
        "    'JPM' : metrics_row('JPM',  df_jpm),\n",
        "}).T.round(4)\n",
        "\n",
        "display(metrics)\n",
        "metrics.to_csv(\"table_forecast_metrics.csv\")\n",
        "\n",
        "import matplotlib.pyplot as plt, matplotlib.dates as mdates\n",
        "\n",
        "def plot_three(df_dict, title=\"\", cumulative=True, save=None):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(14,4), sharey=True, constrained_layout=True)\n",
        "    for ax, (name, df) in zip(axes, df_dict.items()):\n",
        "        d = df.copy()\n",
        "        if cumulative:\n",
        "            d['actual'] = (1 + d['actual']).cumprod() - 1\n",
        "            d['pred']   = (1 + d['pred']).cumprod() - 1\n",
        "        ax.plot(d.index, d['actual'], label=\"Actual (cum excess)\" if cumulative else \"Actual\", color=\"#444\", lw=1.5)\n",
        "        ax.plot(d.index, d['pred'],   label=\"Predicted (cum excess)\" if cumulative else \"Predicted\", color=\"#1f77b4\", lw=1.5)\n",
        "        ax.set_title(name, fontsize=11); ax.grid(alpha=.25)\n",
        "        ax.spines[['top','right']].set_visible(False)\n",
        "        # readable dates\n",
        "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "        ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonth=(3,9)))\n",
        "        ax.tick_params(axis='x', labelsize=9)\n",
        "    axes[0].legend(frameon=False, loc=\"upper left\")\n",
        "    fig.suptitle(title, y=1.02, fontsize=13)\n",
        "    if save: plt.savefig(save, dpi=240, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_three({'NVDA': df_nvda, 'TSLA': df_tsla, 'JPM': df_jpm},\n",
        "           title=\"FF3 1-day-ahead forecasts (cum excess)\", cumulative=True,\n",
        "           save=\"fig_forecasts.png\")\n",
        "def add_naive(df):\n",
        "    # naive forecast = today's excess return as prediction for tomorrow\n",
        "    # shift actual forward by 1 day to align as a prediction\n",
        "    naive = df['actual'].shift(1)\n",
        "    out = df.copy()\n",
        "    out['naive'] = naive\n",
        "    return out.dropna()\n",
        "\n",
        "for name, d in {'NVDA': df_nvda, 'TSLA': df_tsla, 'JPM': df_jpm}.items():\n",
        "    dd = add_naive(d)\n",
        "    rmse_model = np.sqrt(np.mean((dd['pred']-dd['actual'])**2))\n",
        "    rmse_naive = np.sqrt(np.mean((dd['naive']-dd['actual'])**2))\n",
        "    print(f\"{name}: RMSE model={rmse_model:.5f} vs naive={rmse_naive:.5f}\")\n",
        "!pip -q install pandas-datareader\n",
        "import warnings, pandas as pd\n",
        "from pandas_datareader import data as web\n",
        "warnings.filterwarnings(\"ignore\", message=\"date_parser\")  # quiet deprecation msg\n",
        "\n",
        "# FF5 (daily, % units) → decimals\n",
        "ff5 = web.DataReader('F-F_Research_Data_5_Factors_2x3_Daily','famafrench')[0]\n",
        "ff5.index = pd.to_datetime(ff5.index)\n",
        "ff5 = ff5[['Mkt-RF','SMB','HML','RMW','CMA']] / 100.0\n",
        "\n",
        "# Momentum (daily, % units) → decimals\n",
        "mom = web.DataReader('F-F_Momentum_Factor_Daily','famafrench')[0]\n",
        "mom.index = pd.to_datetime(mom.index)\n",
        "mom = mom / 100.0\n",
        "# normalize column name to 'Mom'\n",
        "mom.columns = ['Mom'] if len(mom.columns)==1 else ['Mom']\n",
        "\n",
        "# Risk-free: reuse from your ff3 if present, else fetch\n",
        "try:\n",
        "    rf = ff3[['RF']].copy()\n",
        "except NameError:\n",
        "    ff3_daily = web.DataReader('F-F_Research_Data_Factors_Daily','famafrench')[0]\n",
        "    ff3_daily.index = pd.to_datetime(ff3_daily.index)\n",
        "    rf = (ff3_daily[['RF']] / 100.0)\n",
        "\n",
        "# Master factor table\n",
        "ffX = ff5.join(mom, how='inner').join(rf, how='inner')\n",
        "\n",
        "# Align to your returns index\n",
        "ffX = ffX.loc[rets.index.min():rets.index.max()]\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# factor sets\n",
        "cols_ff3   = [\"Mkt-RF\",\"SMB\",\"HML\"]\n",
        "cols_ff5   = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
        "cols_car4  = [\"Mkt-RF\",\"SMB\",\"HML\",\"Mom\"]\n",
        "cols_ff5m  = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"Mom\"]   # optional: FF5 + Momentum\n",
        "\n",
        "def run_model(dat, ticker, cols):\n",
        "    y = dat[ticker] - dat[\"RF\"]\n",
        "    X = sm.add_constant(dat[cols])\n",
        "    m = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":5})\n",
        "    return m\n",
        "\n",
        "# join factors + RF to returns for each spec (inner join on dates)\n",
        "dat_ff3  = rets.join(ffX[cols_ff3 + [\"RF\"]],  how=\"inner\")\n",
        "dat_ff5  = rets.join(ffX[cols_ff5 + [\"RF\"]],  how=\"inner\")\n",
        "dat_car4 = rets.join(ffX[cols_car4 + [\"RF\"]], how=\"inner\")\n",
        "dat_ff5m = rets.join(ffX[cols_ff5m + [\"RF\"]], how=\"inner\")\n",
        "\n",
        "tickers = list(rets.columns)  # or your own list\n",
        "\n",
        "rows = []\n",
        "for t in tickers:\n",
        "    m3  = run_model(dat_ff3,  t, cols_ff3)\n",
        "    m5  = run_model(dat_ff5,  t, cols_ff5)\n",
        "    m4  = run_model(dat_car4, t, cols_car4)\n",
        "    m6  = run_model(dat_ff5m, t, cols_ff5m)\n",
        "\n",
        "    row = {\n",
        "        \"ticker\": t,\n",
        "        \"R2_FF3\":  m3.rsquared,\n",
        "        \"R2_FF5\":  m5.rsquared,\n",
        "        \"R2_Car4\": m4.rsquared,\n",
        "        \"R2_FF5M\": m6.rsquared,\n",
        "        \"alpha_ann_FF3\":  m3.params[\"const\"] * 252,\n",
        "        \"alpha_ann_FF5\":  m5.params[\"const\"] * 252,\n",
        "        \"alpha_ann_Car4\": m4.params[\"const\"] * 252,\n",
        "        \"alpha_ann_FF5M\": m6.params[\"const\"] * 252,\n",
        "        \"p_alpha_FF3\":  m3.pvalues[\"const\"],\n",
        "        \"p_alpha_FF5\":  m5.pvalues[\"const\"],\n",
        "        \"p_alpha_Car4\": m4.pvalues[\"const\"],\n",
        "        \"p_alpha_FF5M\": m6.pvalues[\"const\"],\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "cmp = pd.DataFrame(rows).set_index(\"ticker\")\n",
        "\n",
        "# add best R2 and delta vs FF3\n",
        "cmp[\"R2_best\"]  = cmp[[\"R2_FF3\",\"R2_FF5\",\"R2_Car4\",\"R2_FF5M\"]].max(axis=1)\n",
        "cmp[\"dR2_best_minus_FF3\"] = cmp[\"R2_best\"] - cmp[\"R2_FF3\"]\n",
        "\n",
        "# clean view for the report\n",
        "view = cmp[[\n",
        "    \"R2_FF3\",\"R2_FF5\",\"R2_Car4\",\"R2_FF5M\",\"R2_best\",\"dR2_best_minus_FF3\",\n",
        "    \"alpha_ann_FF3\",\"alpha_ann_FF5\",\"alpha_ann_Car4\",\"alpha_ann_FF5M\",\n",
        "    \"p_alpha_FF3\",\"p_alpha_FF5\",\"p_alpha_Car4\",\"p_alpha_FF5M\"\n",
        "]].sort_values(\"dR2_best_minus_FF3\", ascending=False)\n",
        "\n",
        "# pretty print\n",
        "display(view.round({\n",
        "    \"R2_FF3\":3,\"R2_FF5\":3,\"R2_Car4\":3,\"R2_FF5M\":3,\"R2_best\":3,\"dR2_best_minus_FF3\":3,\n",
        "    \"alpha_ann_FF3\":3,\"alpha_ann_FF5\":3,\"alpha_ann_Car4\":3,\"alpha_ann_FF5M\":3,\n",
        "    \"p_alpha_FF3\":3,\"p_alpha_FF5\":3,\"p_alpha_Car4\":3,\"p_alpha_FF5M\":3\n",
        "}))\n",
        "\n",
        "# save for LaTeX/Overleaf table\n",
        "view.to_csv(\"table_ff3_vs_ff5.csv\")\n",
        "\n",
        "for t in [\"NVDA\",\"TSLA\",\"JPM\"]:\n",
        "    r = view.loc[t]\n",
        "    best = max(r[\"R2_FF3\"], r[\"R2_FF5\"], r[\"R2_Car4\"], r[\"R2_FF5M\"])\n",
        "    print(\n",
        "        f\"{t}: R² FF3={r['R2_FF3']:.3f}  FF5={r['R2_FF5']:.3f}  Car4={r['R2_Car4']:.3f}  FF5+Mom={r['R2_FF5M']:.3f}  \"\n",
        "        f\"ΔR²(best-FF3)={r['dR2_best_minus_FF3']:.3f}\\n\"\n",
        "        f\"    α_annual FF3={r['alpha_ann_FF3']:.2%} (p={r['p_alpha_FF3']:.3f}), \"\n",
        "        f\"FF5={r['alpha_ann_FF5']:.2%} (p={r['p_alpha_FF5']:.3f}), \"\n",
        "        f\"Car4={r['alpha_ann_Car4']:.2%} (p={r['p_alpha_Car4']:.3f}), \"\n",
        "        f\"FF5+Mom={r['alpha_ann_FF5M']:.2%} (p={r['p_alpha_FF5M']:.3f})\"\n",
        "    )\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "\n",
        "def rolling_ff3_betas(ticker, window=252, step=1, cov_type='HAC', hac_lags=5):\n",
        "    \"\"\"\n",
        "    Rolling FF3 regressions for `ticker`.\n",
        "      - window: trailing window length in trading days (252 ~ 1y)\n",
        "      - step: move the window by this many days each iteration (e.g., 5 ≈ weekly endpoints)\n",
        "      - cov_type: None (classic OLS SEs) or 'HAC' (Newey–West)\n",
        "      - hac_lags: maxlags for HAC SEs (5 ≈ one trading week)\n",
        "    Returns: DataFrame indexed by window end date with betas, alpha, R², and SEs.\n",
        "    \"\"\"\n",
        "    y = (data[ticker] - data['RF']).dropna()\n",
        "    Xf = data[['Mkt-RF','SMB','HML']].loc[y.index]\n",
        "\n",
        "    rows = []\n",
        "    for end in range(window, len(y)+1, step):\n",
        "        Yw = y.iloc[end-window:end]\n",
        "        Xw = sm.add_constant(Xf.iloc[end-window:end])\n",
        "        if cov_type == 'HAC':\n",
        "            m = sm.OLS(Yw, Xw).fit(cov_type='HAC', cov_kwds={'maxlags': hac_lags})\n",
        "        else:\n",
        "            m = sm.OLS(Yw, Xw).fit()\n",
        "\n",
        "        date = y.index[end-1]\n",
        "        rows.append({\n",
        "            'Date': date,\n",
        "            'beta_mkt': m.params['Mkt-RF'],\n",
        "            'beta_smb': m.params['SMB'],\n",
        "            'beta_hml': m.params['HML'],\n",
        "            'se_beta_mkt': m.bse['Mkt-RF'],\n",
        "            'se_beta_smb': m.bse['SMB'],\n",
        "            'se_beta_hml': m.bse['HML'],\n",
        "            'alpha_daily': m.params['const'],\n",
        "            'alpha_annual': m.params['const'] * 252,\n",
        "            'r2': m.rsquared,\n",
        "            'n': int(m.nobs),\n",
        "        })\n",
        "\n",
        "    rb = pd.DataFrame(rows).set_index('Date')\n",
        "    return rb\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt, matplotlib.dates as mdates\n",
        "\n",
        "# run (change step=5 for faster, weekly endpoints)\n",
        "rb_nvda = rolling_ff3_betas('NVDA', window=252, step=1, cov_type='HAC', hac_lags=5)\n",
        "\n",
        "# 95% CI bands\n",
        "ci = 1.96\n",
        "u_mkt = rb_nvda['beta_mkt'] + ci*rb_nvda['se_beta_mkt']\n",
        "l_mkt = rb_nvda['beta_mkt'] - ci*rb_nvda['se_beta_mkt']\n",
        "u_smb = rb_nvda['beta_smb'] + ci*rb_nvda['se_beta_smb']\n",
        "l_smb = rb_nvda['beta_smb'] - ci*rb_nvda['se_beta_smb']\n",
        "u_hml = rb_nvda['beta_hml'] + ci*rb_nvda['se_beta_hml']\n",
        "l_hml = rb_nvda['beta_hml'] - ci*rb_nvda['se_beta_hml']\n",
        "\n",
        "# --- Betas with CIs ---\n",
        "fig, axes = plt.subplots(3,1, figsize=(12,8), sharex=True, constrained_layout=True)\n",
        "\n",
        "axes[0].plot(rb_nvda.index, rb_nvda['beta_mkt'], color='C0', label=r'$\\beta_{\\mathrm{Mkt}}$')\n",
        "axes[0].fill_between(rb_nvda.index, l_mkt, u_mkt, color='C0', alpha=0.15, linewidth=0)\n",
        "axes[0].axhline(0, color='k', lw=1, alpha=.6); axes[0].set_ylabel('Mkt beta')\n",
        "\n",
        "axes[1].plot(rb_nvda.index, rb_nvda['beta_smb'], color='C1', label=r'$\\beta_{\\mathrm{SMB}}$')\n",
        "axes[1].fill_between(rb_nvda.index, l_smb, u_smb, color='C1', alpha=0.15, linewidth=0)\n",
        "axes[1].axhline(0, color='k', lw=1, alpha=.6); axes[1].set_ylabel('SMB beta')\n",
        "\n",
        "axes[2].plot(rb_nvda.index, rb_nvda['beta_hml'], color='C2', label=r'$\\beta_{\\mathrm{HML}}$')\n",
        "axes[2].fill_between(rb_nvda.index, l_hml, u_hml, color='C2', alpha=0.15, linewidth=0)\n",
        "axes[2].axhline(0, color='k', lw=1, alpha=.6); axes[2].set_ylabel('HML beta')\n",
        "\n",
        "for ax in axes:\n",
        "    ax.grid(alpha=.25); ax.spines[['top','right']].set_visible(False)\n",
        "\n",
        "axes[-1].xaxis.set_major_locator(mdates.YearLocator())\n",
        "axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "axes[-1].xaxis.set_minor_locator(mdates.MonthLocator(bymonth=(3,9)))\n",
        "axes[-1].set_xlabel('Date')\n",
        "\n",
        "fig.suptitle('NVDA — Rolling 1Y Fama–French Betas (HAC 95% CI)', y=1.02, fontsize=13)\n",
        "plt.savefig('fig_rolling_beta_NVDA.png', dpi=240, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# --- Alpha & R² (handy for appendix) ---\n",
        "fig, ax2 = plt.subplots(2,1, figsize=(12,5), sharex=True, constrained_layout=True)\n",
        "ax2[0].plot(rb_nvda.index, rb_nvda['alpha_annual']*100, color='#555')\n",
        "ax2[0].axhline(0, color='k', lw=1, alpha=.6); ax2[0].set_ylabel('Alpha (annual, %)')\n",
        "ax2[1].plot(rb_nvda.index, rb_nvda['r2'], color='#1f77b4')\n",
        "ax2[1].set_ylabel(r'$R^2$'); ax2[1].set_xlabel('Date')\n",
        "for a in ax2: a.grid(alpha=.25); a.spines[['top','right']].set_visible(False)\n",
        "ax2[-1].xaxis.set_major_locator(mdates.YearLocator())\n",
        "ax2[-1].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "plt.savefig('fig_nvda_alpha_r2.png', dpi=240, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# quick summary for your write-up\n",
        "print(rb_nvda[['beta_mkt','beta_smb','beta_hml','alpha_annual','r2']].tail(3).round(3))\n",
        "print(\"Latest betas:\", rb_nvda.iloc[-1][['beta_mkt','beta_smb','beta_hml']].round(3).to_dict())\n",
        "\n",
        "\n",
        "print(\"Sample window:\", data.index.min(), \"→\", data.index.max())\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "\n",
        "def fit_ff3_segment(df, ticker, hac_lags=5):\n",
        "    y = df[ticker] - df[\"RF\"]\n",
        "    X = sm.add_constant(df[[\"Mkt-RF\",\"SMB\",\"HML\"]])\n",
        "    m = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":hac_lags})\n",
        "    return {\n",
        "        \"alpha_daily\":  m.params[\"const\"],\n",
        "        \"alpha_annual\": m.params[\"const\"]*252,\n",
        "        \"beta_mkt\":     m.params[\"Mkt-RF\"],\n",
        "        \"beta_smb\":     m.params[\"SMB\"],\n",
        "        \"beta_hml\":     m.params[\"HML\"],\n",
        "        \"p_alpha\":      m.pvalues[\"const\"],\n",
        "        \"r2\":           m.rsquared,\n",
        "        \"n\":            int(m.nobs),\n",
        "    }, m\n",
        "\n",
        "def choose_valid_split(ticker, preferred_split, min_obs=252):\n",
        "    df = data[[ticker,\"Mkt-RF\",\"SMB\",\"HML\",\"RF\"]].dropna()\n",
        "    idx = df.index; n = len(idx)\n",
        "    if n < 2*min_obs + 1:\n",
        "        return None, f\"Not enough total obs (n={n}) for min_obs={min_obs} on each side.\"\n",
        "    pos_pref = np.searchsorted(idx.values, np.datetime64(preferred_split))\n",
        "    lo = min_obs\n",
        "    hi = n - min_obs - 1\n",
        "    pos = min(max(pos_pref, lo), hi)\n",
        "    split = idx[pos]\n",
        "    note = \"\" if (lo <= pos_pref <= hi) else f\"Preferred split {preferred_split.date()} adjusted to {split.date()}.\"\n",
        "    return split, note\n",
        "\n",
        "ALL_COLS = [\n",
        "    \"pre_beta_mkt\",\"post_beta_mkt\",\"Δbeta_mkt\",\"p(Δbeta_mkt)\",\n",
        "    \"pre_beta_smb\",\"post_beta_smb\",\"Δbeta_smb\",\"p(Δbeta_smb)\",\n",
        "    \"pre_beta_hml\",\"post_beta_hml\",\"Δbeta_hml\",\"p(Δbeta_hml)\",\n",
        "    \"pre_alpha_ann\",\"post_alpha_ann\",\"Δalpha_ann\",\"p(Δalpha)\",\n",
        "    \"pre_R2\",\"post_R2\",\"pre_n\",\"post_n\",\"note\"\n",
        "]\n",
        "\n",
        "def pre_post_stability_safe(ticker, preferred_split, min_obs=252, hac_lags=5):\n",
        "    # initialize row with NaNs so required columns *always* exist\n",
        "    res = {k: np.nan for k in ALL_COLS}\n",
        "    res[\"ticker\"] = ticker\n",
        "\n",
        "    split, note = choose_valid_split(ticker, preferred_split, min_obs=min_obs)\n",
        "    if split is None:\n",
        "        res[\"note\"] = note\n",
        "        return res\n",
        "\n",
        "    df = data[[ticker,\"Mkt-RF\",\"SMB\",\"HML\",\"RF\"]].dropna()\n",
        "    pre  = df.loc[:split]\n",
        "    post = df.loc[split + pd.Timedelta(days=1):]\n",
        "\n",
        "    pre_stats,  _ = fit_ff3_segment(pre,  ticker, hac_lags)\n",
        "    post_stats, _ = fit_ff3_segment(post, ticker, hac_lags)\n",
        "\n",
        "    # interaction test\n",
        "    full = df.copy()\n",
        "    full[\"POST\"] = (full.index > split).astype(int)\n",
        "    for c in [\"Mkt-RF\",\"SMB\",\"HML\"]:\n",
        "        full[f\"{c}_POST\"] = full[c]*full[\"POST\"]\n",
        "    y = full[ticker] - full[\"RF\"]\n",
        "    X = sm.add_constant(full[[\"Mkt-RF\",\"SMB\",\"HML\",\"POST\",\"Mkt-RF_POST\",\"SMB_POST\",\"HML_POST\"]])\n",
        "    m_int = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":hac_lags})\n",
        "\n",
        "    res.update({\n",
        "        \"pre_beta_mkt\":  pre_stats[\"beta_mkt\"],  \"post_beta_mkt\":  post_stats[\"beta_mkt\"],\n",
        "        \"Δbeta_mkt\":     m_int.params[\"Mkt-RF_POST\"], \"p(Δbeta_mkt)\": m_int.pvalues[\"Mkt-RF_POST\"],\n",
        "        \"pre_beta_smb\":  pre_stats[\"beta_smb\"],  \"post_beta_smb\":  post_stats[\"beta_smb\"],\n",
        "        \"Δbeta_smb\":     m_int.params[\"SMB_POST\"],    \"p(Δbeta_smb)\": m_int.pvalues[\"SMB_POST\"],\n",
        "        \"pre_beta_hml\":  pre_stats[\"beta_hml\"],  \"post_beta_hml\":  post_stats[\"beta_hml\"],\n",
        "        \"Δbeta_hml\":     m_int.params[\"HML_POST\"],    \"p(Δbeta_hml)\": m_int.pvalues[\"HML_POST\"],\n",
        "        \"pre_alpha_ann\": pre_stats[\"alpha_annual\"], \"post_alpha_ann\": post_stats[\"alpha_annual\"],\n",
        "        \"Δalpha_ann\":    m_int.params[\"POST\"]*252,    \"p(Δalpha)\":     m_int.pvalues[\"POST\"],\n",
        "        \"pre_R2\": pre_stats[\"r2\"], \"post_R2\": post_stats[\"r2\"],\n",
        "        \"pre_n\":  pre_stats[\"n\"],  \"post_n\":  post_stats[\"n\"],\n",
        "        \"note\":   note if note else f\"Split at {split.date()}\",\n",
        "    })\n",
        "    return res\n",
        "preferred_split = pd.Timestamp(\"2022-01-01\")   # <- good for your window\n",
        "rows = [pre_post_stability_safe(t, preferred_split, min_obs=252) for t in [\"NVDA\",\"TSLA\",\"JPM\"]]\n",
        "prepost = pd.DataFrame(rows).set_index(\"ticker\")[ALL_COLS]   # enforce all columns\n",
        "display(prepost.round(4))\n",
        "prepost.round(4).to_csv(\"table_pre_post_covid.csv\")\n",
        "\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "r = prepost.loc[\"NVDA\"]\n",
        "if np.isfinite(r[\"pre_beta_mkt\"]) and np.isfinite(r[\"post_beta_mkt\"]):\n",
        "    labels = [\"Mkt\",\"SMB\",\"HML\"]\n",
        "    pre_b  = [r[\"pre_beta_mkt\"], r[\"pre_beta_smb\"], r[\"pre_beta_hml\"]]\n",
        "    post_b = [r[\"post_beta_mkt\"], r[\"post_beta_smb\"], r[\"post_beta_hml\"]]\n",
        "    pvals  = [r[\"p(Δbeta_mkt)\"], r[\"p(Δbeta_smb)\"], r[\"p(Δbeta_hml)\"]]\n",
        "\n",
        "    x = np.arange(3); w=0.35\n",
        "    plt.figure(figsize=(6.2,4.2))\n",
        "    plt.bar(x-w/2, pre_b,  width=w, label=\"Pre\")\n",
        "    plt.bar(x+w/2, post_b, width=w, label=\"Post\")\n",
        "    for i,p in enumerate(pvals):\n",
        "        txt = f\"p={p:.3f}\" if np.isfinite(p) else \"p=NA\"\n",
        "        ymax = max(pre_b[i], post_b[i])\n",
        "        plt.text(x[i], ymax + 0.05, txt, ha='center', fontsize=9)\n",
        "    plt.axhline(0, color='k', lw=1)\n",
        "    plt.xticks(x, labels); plt.ylabel(\"Beta\")\n",
        "    plt.title(f\"NVDA betas: pre vs post  •  {prepost.loc['NVDA','note']}\")\n",
        "    plt.legend(frameon=False); plt.tight_layout(); plt.show()\n",
        "else:\n",
        "    print(\"NVDA: not enough obs on one side — try lowering min_obs or moving the split later (e.g., 2022-06-01).\")\n",
        "\n",
        "r = prepost.loc[\"NVDA\"]\n",
        "print({\n",
        "  \"pre_beta_mkt\":  r[\"pre_beta_mkt\"],\n",
        "  \"post_beta_mkt\": r[\"post_beta_mkt\"],\n",
        "  \"p_d_beta_mkt\":  r[\"p(Δbeta_mkt)\"],\n",
        "  \"pre_beta_smb\":  r[\"pre_beta_smb\"],\n",
        "  \"post_beta_smb\": r[\"post_beta_smb\"],\n",
        "  \"p_d_beta_smb\":  r[\"p(Δbeta_smb)\"],\n",
        "  \"pre_beta_hml\":  r[\"pre_beta_hml\"],\n",
        "  \"post_beta_hml\": r[\"post_beta_hml\"],\n",
        "  \"p_d_beta_hml\":  r[\"p(Δbeta_hml)\"],\n",
        "  \"pre_alpha_ann\": r[\"pre_alpha_ann\"],\n",
        "  \"post_alpha_ann\":r[\"post_alpha_ann\"],\n",
        "  \"pre_R2\":        r[\"pre_R2\"],\n",
        "  \"post_R2\":       r[\"post_R2\"],\n",
        "  \"note\":          r[\"note\"],\n",
        "})\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "\n",
        "# ----- helpers -----\n",
        "# infer tickers from `data`\n",
        "FFCOLS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RF\"]\n",
        "tickers = [c for c in data.columns if c not in FFCOLS]\n",
        "\n",
        "def get_betas(ticker):\n",
        "    \"\"\"Return (alpha, beta_mkt, beta_smb, beta_hml) for `ticker` using full-sample OLS,\n",
        "       unless a `models[ticker]` already exists.\"\"\"\n",
        "    try:\n",
        "        b = models[ticker].params  # const, Mkt-RF, SMB, HML\n",
        "        return float(b['const']), float(b['Mkt-RF']), float(b['SMB']), float(b['HML'])\n",
        "    except Exception:\n",
        "        y = data[ticker] - data[\"RF\"]\n",
        "        X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]])\n",
        "        m = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "        b = m.params\n",
        "        return float(b['const']), float(b['Mkt-RF']), float(b['SMB']), float(b['HML'])\n",
        "\n",
        "def scenario_excess(alpha, bm, bs, bh, mkt_rf, smb, hml):\n",
        "    \"\"\"Expected *excess* return under scenario (daily, decimal).\"\"\"\n",
        "    return alpha + bm*mkt_rf + bs*smb + bh*hml\n",
        "\n",
        "# ----- define scenarios (daily decimals) -----\n",
        "scenarios = pd.DataFrame([\n",
        "    {\"Scenario\":\"Risk-on +2% market\",          \"Mkt-RF\":0.0200, \"SMB\": 0.000, \"HML\": 0.000},\n",
        "    {\"Scenario\":\"Mkt +1%, small +0.3%, value -0.3%\",\"Mkt-RF\":0.0100, \"SMB\": 0.003, \"HML\":-0.003},\n",
        "    {\"Scenario\":\"Risk-off -1% market, small -0.3%, value +0.3%\",\"Mkt-RF\":-0.0100, \"SMB\":-0.003, \"HML\": 0.003},\n",
        "    {\"Scenario\":\"Flat factors (alpha only)\",   \"Mkt-RF\":0.0000, \"SMB\": 0.000, \"HML\": 0.000},\n",
        "])\n",
        "\n",
        "# choose an RF for \"total\" scenario returns; use recent mean RF\n",
        "rf_daily = float(data[\"RF\"].mean())\n",
        "\n",
        "# ----- scenario table -----\n",
        "out = scenarios.copy()\n",
        "for t in tickers:\n",
        "    a,bm,bs,bh = get_betas(t)\n",
        "    out[f\"{t}_excess\"] = out.apply(lambda r: scenario_excess(a,bm,bs,bh,\n",
        "                                   r[\"Mkt-RF\"], r[\"SMB\"], r[\"HML\"]), axis=1)\n",
        "    out[f\"{t}_total\"]  = out[f\"{t}_excess\"] + rf_daily\n",
        "\n",
        "# tidy view (two tables): excess and total\n",
        "excess_cols = [\"Scenario\"] + [f\"{t}_excess\" for t in tickers]\n",
        "total_cols  = [\"Scenario\"] + [f\"{t}_total\"  for t in tickers]\n",
        "\n",
        "scen_excess = out[excess_cols].set_index(\"Scenario\").sort_index(axis=1)\n",
        "scen_total  = out[total_cols ].set_index(\"Scenario\").sort_index(axis=1)\n",
        "\n",
        "print(\"Scenario (daily *excess* return, decimals):\")\n",
        "display(scen_excess.round(4))\n",
        "print(\"Scenario (daily *total* return, decimals):\")\n",
        "display(scen_total.round(4))\n",
        "\n",
        "# export for report\n",
        "scen_excess.to_csv(\"table_scenarios_excess.csv\")\n",
        "scen_total.to_csv(\"table_scenarios_total.csv\")\n",
        "\n",
        "import pandas as pd, numpy as np, statsmodels.api as sm\n",
        "\n",
        "# factor premia (daily means) over sample\n",
        "mu = data[[\"Mkt-RF\",\"SMB\",\"HML\"]].mean()\n",
        "rf_daily = float(data[\"RF\"].mean())\n",
        "\n",
        "rows = []\n",
        "for t in tickers:\n",
        "    # betas (reused from A)\n",
        "    alpha, bm, bs, bh = get_betas(t)\n",
        "    exp_excess_daily = float(alpha + bm*mu[\"Mkt-RF\"] + bs*mu[\"SMB\"] + bh*mu[\"HML\"])\n",
        "    exp_excess_annual = exp_excess_daily * 252\n",
        "    exp_total_annual  = exp_excess_annual + rf_daily * 252\n",
        "    rows.append([t, exp_excess_daily, exp_excess_annual, exp_total_annual])\n",
        "\n",
        "exp_table = pd.DataFrame(rows, columns=[\"Ticker\",\"E_excess_daily\",\"E_excess_annual\",\"E_total_annual\"])\n",
        "display(exp_table.set_index(\"Ticker\").round(4))\n",
        "\n",
        "# export for Overleaf\n",
        "exp_table.to_csv(\"table_expected_returns.csv\", index=False)\n",
        "\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "sns.heatmap(scen_excess*100, annot=True, fmt=\".2f\", cmap=\"RdYlBu_r\")\n",
        "plt.title(\"Scenario: expected *excess* returns (daily, %)\")\n",
        "plt.ylabel(\"\"); plt.show()\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "\n",
        "def rolling_ff3_forecast_oos(data, ticker, window=252, use_ar1=True, min_len_ar=30):\n",
        "    \"\"\"\n",
        "    True 1-day-ahead OOS forecast of EXCESS return for `ticker`.\n",
        "      - Betas: OLS on trailing `window` days.\n",
        "      - Factor forecasts: AR(1) on each factor up to t (fallback = last value).\n",
        "      - Returns: DataFrame with ['actual','pred'] and metrics dict.\n",
        "    \"\"\"\n",
        "    y_excess = (data[ticker] - data[\"RF\"]).dropna()\n",
        "    fac = data[[\"Mkt-RF\",\"SMB\",\"HML\"]].loc[y_excess.index]\n",
        "\n",
        "    preds = pd.Series(index=y_excess.index, dtype=float)\n",
        "\n",
        "    for i in range(window, len(y_excess)-1):\n",
        "        # 1) betas on [i-window, i)\n",
        "        Yw = y_excess.iloc[i-window:i]\n",
        "        Xw = sm.add_constant(fac.iloc[i-window:i])\n",
        "        b  = sm.OLS(Yw, Xw).fit().params\n",
        "\n",
        "        # 2) forecasting factors for t+1\n",
        "        if use_ar1:\n",
        "            fhat = {}\n",
        "            for col in fac.columns:\n",
        "                series = fac[col].iloc[:i].dropna()\n",
        "                if len(series) >= min_len_ar:\n",
        "                    sr = pd.Series(series.to_numpy())               # RangeIndex -> no AR warnings\n",
        "                    ar = AutoReg(sr, lags=1, old_names=False).fit()\n",
        "                    fhat[col] = float(ar.forecast(steps=1).iloc[0])\n",
        "                else:\n",
        "                    fhat[col] = float(series.iloc[-1])              # persistence fallback\n",
        "        else:\n",
        "            fhat = fac.iloc[i].to_dict()                            # pure persistence\n",
        "\n",
        "        next_idx = y_excess.index[i+1]\n",
        "        preds.loc[next_idx] = (\n",
        "            b['const'] + b['Mkt-RF']*fhat['Mkt-RF'] +\n",
        "            b['SMB']*fhat['SMB'] + b['HML']*fhat['HML']\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame({\"pred\": preds, \"actual\": y_excess}).dropna()\n",
        "    rmse = float(np.sqrt(np.mean((df['pred']-df['actual'])**2)))\n",
        "    corr = float(df['pred'].corr(df['actual']))\n",
        "    hit  = float((np.sign(df['pred']) == np.sign(df['actual'])).mean())\n",
        "    return df, {\"RMSE\": rmse, \"Corr\": corr, \"HitRate\": hit}\n",
        "\n",
        "tickers = [\"NVDA\",\"TSLA\",\"JPM\"]\n",
        "\n",
        "series = {}\n",
        "metrics = {}\n",
        "for t in tickers:\n",
        "    df, m = rolling_ff3_forecast_oos(data, t, window=252, use_ar1=True)\n",
        "    series[t]  = df\n",
        "    metrics[t] = m\n",
        "    print(t, m)\n",
        "\n",
        "# metrics table\n",
        "met_tbl = pd.DataFrame(metrics).T\n",
        "display(met_tbl.round(4))\n",
        "met_tbl.round(6).to_csv(\"table_forecast_metrics.csv\")\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def add_naive_and_compare(df):\n",
        "    # naive(shift by +1)\n",
        "    d = df.copy()\n",
        "    d['naive'] = d['actual'].shift(1)\n",
        "    d = d.dropna()\n",
        "    rmse_model = float(np.sqrt(np.mean((d['pred'] - d['actual'])**2)))\n",
        "    rmse_naive = float(np.sqrt(np.mean((d['naive']- d['actual'])**2)))\n",
        "    impr = (rmse_naive - rmse_model) / rmse_naive  # + = model better\n",
        "    return rmse_model, rmse_naive, impr\n",
        "\n",
        "rows = []\n",
        "for t, df in series.items():\n",
        "    rm_m, rm_n, impr = add_naive_and_compare(df)\n",
        "    rows.append([t, rm_m, rm_n, impr])\n",
        "cmp_tbl = pd.DataFrame(rows, columns=[\"Ticker\",\"RMSE_model\",\"RMSE_naive\",\"Improvement_vs_naive\"])\n",
        "display(cmp_tbl.round(4))\n",
        "cmp_tbl.round(6).to_csv(\"table_forecast_vs_naive.csv\", index=False)\n",
        "\n",
        "def verify_oos(ticker, df, window=252):\n",
        "    y = (data[ticker]-data['RF']).dropna()\n",
        "    print(ticker, \"| full start:\", y.index.min(), \"| expected first forecast:\", y.index[window+1], \"| df start:\", df.index.min())\n",
        "for t in tickers:\n",
        "    verify_oos(t, series[t])\n",
        "import matplotlib.pyplot as plt, matplotlib.dates as mdates\n",
        "\n",
        "# bias-correct (for cumulative visual only)\n",
        "def bias_correct_df(df):\n",
        "    d = df.copy()\n",
        "    bias = (d['pred'] - d['actual']).mean()\n",
        "    d['pred_bc'] = d['pred'] - bias\n",
        "    return d\n",
        "\n",
        "def plot_oos_daily(series, fname=None):\n",
        "    fig, axes = plt.subplots(1, len(series), figsize=(14,4), sharey=True, constrained_layout=True)\n",
        "    if len(series)==1: axes=[axes]\n",
        "    for ax, (name, df) in zip(axes, series.items()):\n",
        "        ax.plot(df.index, df['actual'], label=\"Actual\", color=\"#444\", lw=1.5)\n",
        "        ax.plot(df.index, df['pred'],   label=\"Predicted\", color=\"#1f77b4\", lw=1.3)\n",
        "        ax.set_title(name); ax.grid(alpha=.25); ax.spines[['top','right']].set_visible(False)\n",
        "        ax.xaxis.set_major_locator(mdates.YearLocator()); ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    axes[0].legend(frameon=False, loc=\"upper left\")\n",
        "    fig.suptitle(\"FF3 1-day-ahead forecasts (daily excess)\", y=1.02)\n",
        "    if fname: plt.savefig(fname, dpi=240, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_oos_cum_bc(series, fname=None):\n",
        "    fig, axes = plt.subplots(1, len(series), figsize=(14,4), sharey=True, constrained_layout=True)\n",
        "    if len(series)==1: axes=[axes]\n",
        "    for ax, (name, df) in zip(axes, series.items()):\n",
        "        d = bias_correct_df(df)\n",
        "        ax.plot(d.index, (1+d['actual']).cumprod()-1, label=\"Actual (cum excess)\", color=\"#444\", lw=1.5)\n",
        "        ax.plot(d.index, (1+d['pred_bc']).cumprod()-1, label=\"Predicted (cum, bias-corr.)\", color=\"#1f77b4\", lw=1.3)\n",
        "        ax.set_title(name); ax.grid(alpha=.25); ax.spines[['top','right']].set_visible(False)\n",
        "        ax.xaxis.set_major_locator(mdates.YearLocator()); ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    axes[0].legend(frameon=False, loc=\"upper left\")\n",
        "    fig.suptitle(\"FF3 1-day-ahead forecasts (cumulative, bias-corrected)\", y=1.02)\n",
        "    if fname: plt.savefig(fname, dpi=240, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_oos_daily(series, fname=\"fig_oos_daily.png\")\n",
        "plot_oos_cum_bc(series, fname=\"fig_oos_cum_bc.png\")\n",
        "\n",
        "import matplotlib.pyplot as plt, matplotlib.dates as mdates\n",
        "\n",
        "def plot_oos_daily_zoom(series, ylim=0.05, title=\"FF3 1-day-ahead forecasts (daily excess, zoomed)\"):\n",
        "    fig, axes = plt.subplots(1, len(series), figsize=(14,4), sharey=True, constrained_layout=True)\n",
        "    if len(series)==1: axes=[axes]\n",
        "    for ax, (name, df) in zip(axes, series.items()):\n",
        "        ax.plot(df.index, df['actual'], label=\"Actual\", color=\"#444\", lw=1)\n",
        "        ax.plot(df.index, df['pred'],   label=\"Predicted\", color=\"#1f77b4\", lw=1.2)\n",
        "        ax.set_ylim(-ylim, ylim)\n",
        "        ax.grid(alpha=.25); ax.spines[['top','right']].set_visible(False)\n",
        "        ax.set_title(name); ax.xaxis.set_major_locator(mdates.YearLocator()); ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    axes[0].legend(frameon=False, loc=\"upper left\")\n",
        "    fig.suptitle(title, y=1.02); plt.show()\n",
        "\n",
        "plot_oos_daily_zoom(series, ylim=0.04)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "def calib_and_residuals(df, name):\n",
        "    fig, ax = plt.subplots(1,2,figsize=(10,4), constrained_layout=True)\n",
        "    sns.regplot(x='pred', y='actual', data=df, scatter_kws={'s':8,'alpha':0.25}, line_kws={'color':'crimson'}, ax=ax[0])\n",
        "    ax[0].axhline(0,color='k',lw=1,alpha=.5); ax[0].axvline(0,color='k',lw=1,alpha=.5)\n",
        "    ax[0].set_title(f\"{name}: calibration (daily)\")\n",
        "    ax[0].set_xlabel(\"Predicted\"); ax[0].set_ylabel(\"Actual\")\n",
        "\n",
        "    res = (df['actual']-df['pred']).dropna()\n",
        "    sns.histplot(res, bins=50, kde=True, color=\"#1f77b4\", ax=ax[1])\n",
        "    ax[1].axvline(0,color='k',lw=1); ax[1].set_title(f\"{name}: residuals\")\n",
        "    plt.show()\n",
        "\n",
        "for name, df in series.items():\n",
        "    calib_and_residuals(df, name)\n",
        "for name, df in series.items():\n",
        "    rc = df['actual'].rolling(63).corr(df['pred'])\n",
        "    rc.plot(label=name, figsize=(10,3))\n",
        "plt.axhline(0,color='k',lw=1); plt.title(\"Rolling 3-month corr(actual, pred)\"); plt.legend(); plt.show()\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "\n",
        "#VaR ES\n",
        "tickers = [\"NVDA\",\"TSLA\",\"JPM\"]\n",
        "\n",
        "def fit_ff3_all(data, tickers):\n",
        "    models, fits = {}, {}\n",
        "    for t in tickers:\n",
        "        y = (data[t] - data[\"RF\"]).dropna()\n",
        "        X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]].loc[y.index])\n",
        "        m = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "        resid = m.resid.dropna()\n",
        "        fits[t] = {\n",
        "            \"alpha\": float(m.params[\"const\"]),\n",
        "            \"betas\": m.params[[\"Mkt-RF\",\"SMB\",\"HML\"]].to_numpy(),   # shape (3,)\n",
        "            \"sigma_eps\": float(resid.std(ddof=1)),\n",
        "            \"n\": int(m.nobs)\n",
        "        }\n",
        "        models[t] = m\n",
        "    return models, fits\n",
        "\n",
        "models, fits = fit_ff3_all(data, tickers)\n",
        "\n",
        "# factor mean & covariance (shrinkage for stability)\n",
        "F = data[[\"Mkt-RF\",\"SMB\",\"HML\"]].dropna()\n",
        "mu_f = F.mean().to_numpy()\n",
        "try:\n",
        "    from sklearn.covariance import LedoitWolf\n",
        "    Sigma_f = LedoitWolf().fit(F.values).covariance_\n",
        "except Exception:\n",
        "    Sigma_f = np.cov(F.values.T)   # fallback\n",
        "rf_daily = float(data[\"RF\"].mean())\n",
        "print(\"Factor means:\", mu_f, \"\\nRF (daily):\", rf_daily)\n",
        "\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def simulate_excess_matrix(tickers, fits, mu_f, Sigma_f, rf_daily, n_sims=100_000, seed=42):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      - r_excess: (n_sims x T) simulated EXCESS returns for all tickers\n",
        "      - r_total : (n_sims x T) simulated TOTAL returns for all tickers\n",
        "    Model: r_i = alpha_i + beta_i' F + eps_i,  F ~ N(mu_f, Sigma_f), eps_i ~ N(0, sigma_eps_i^2)\n",
        "    \"\"\"\n",
        "    T = len(tickers)\n",
        "    alphas = np.array([fits[t][\"alpha\"]      for t in tickers])          # (T,)\n",
        "    betas  = np.vstack([fits[t][\"betas\"]     for t in tickers])          # (T,3)\n",
        "    sig    = np.array([fits[t][\"sigma_eps\"]  for t in tickers])          # (T,)\n",
        "\n",
        "    rng = default_rng(seed)\n",
        "    Fsim = rng.multivariate_normal(mean=mu_f, cov=Sigma_f, size=n_sims)  # (n,3)\n",
        "    eps  = rng.normal(loc=0.0, scale=sig, size=(n_sims, T))              # (n,T)\n",
        "\n",
        "    r_excess = alphas[None, :] + Fsim @ betas.T + eps                    # (n,T)\n",
        "    r_total  = r_excess + rf_daily                                       # (n,T)\n",
        "    return r_excess, r_total\n",
        "\n",
        "def var_es_cols(r, q=0.95):\n",
        "    \"\"\"VaR/ES for each column of r (returns, not losses). Positive VaR/ES = % loss.\"\"\"\n",
        "    p = 1 - q\n",
        "    VaR, ES = np.zeros(r.shape[1]), np.zeros(r.shape[1])\n",
        "    for j in range(r.shape[1]):\n",
        "        col = r[:, j]\n",
        "        cut = np.quantile(col, p)\n",
        "        VaR[j] = -cut\n",
        "        ES[j]  = -col[col <= cut].mean()\n",
        "    return VaR, ES\n",
        "\n",
        "def var_es_series(x, q=0.95):\n",
        "    p = 1 - q\n",
        "    cut = np.quantile(x, p)\n",
        "    VaR = -cut\n",
        "    ES  = -x[x <= cut].mean()\n",
        "    return VaR, ES\n",
        "# simulate\n",
        "r_excess, r_total = simulate_excess_matrix(tickers, fits, mu_f, Sigma_f, rf_daily, n_sims=200_000, seed=7)\n",
        "\n",
        "# per-ticker VaR/ES\n",
        "VaR_ex, ES_ex = var_es_cols(r_excess, q=0.95)\n",
        "VaR_to, ES_to = var_es_cols(r_total,  q=0.95)\n",
        "\n",
        "tbl = pd.DataFrame({\n",
        "    \"VaR95_excess\": VaR_ex,\n",
        "    \"ES95_excess\":  ES_ex,\n",
        "    \"VaR95_total\":  VaR_to,\n",
        "    \"ES95_total\":   ES_to,\n",
        "    \"alpha_annual\": [fits[t][\"alpha\"]*252 for t in tickers],\n",
        "    \"resid_sigma\":  [fits[t][\"sigma_eps\"] for t in tickers],\n",
        "    \"n_obs\":        [fits[t][\"n\"]         for t in tickers],\n",
        "}, index=tickers).sort_index()\n",
        "\n",
        "display(tbl.round(4))\n",
        "\n",
        "# equal-weight portfolio\n",
        "w = np.repeat(1/len(tickers), len(tickers))\n",
        "r_ex_port = r_excess @ w\n",
        "r_to_port  = r_total  @ w\n",
        "VaR_ex_p, ES_ex_p = var_es_series(r_ex_port, q=0.95)\n",
        "VaR_to_p, ES_to_p = var_es_series(r_to_port,  q=0.95)\n",
        "\n",
        "port_row = pd.DataFrame({\n",
        "    \"VaR95_excess\": [VaR_ex_p],\n",
        "    \"ES95_excess\":  [ES_ex_p],\n",
        "    \"VaR95_total\":  [VaR_to_p],\n",
        "    \"ES95_total\":   [ES_to_p],\n",
        "}, index=[\"EQW_PORT\"])\n",
        "\n",
        "tbl_all = pd.concat([tbl, port_row])\n",
        "tbl_all.round(6).to_csv(\"table_var_es.csv\")\n",
        "print(\"\\nSaved: table_var_es.csv\")\n",
        "display(tbl_all.round(4))\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "\n",
        "name = \"NVDA\"\n",
        "j = tickers.index(name)\n",
        "sns.kdeplot(r_excess[:, j], fill=True, color=\"#1f77b4\", label=\"Excess (MC)\")\n",
        "plt.axvline(-tbl.loc[name,\"VaR95_excess\"], color=\"crimson\", ls=\"--\", label=\"VaR95\")\n",
        "plt.title(f\"{name} — Monte Carlo excess-return distribution (1-day)\")\n",
        "plt.xlabel(\"Return (daily, decimal)\"); plt.legend(); plt.show()\n",
        "\n",
        "# data = rets.join(ff3[['Mkt-RF','SMB','HML','RF']], how='inner').dropna()\n",
        "\n",
        "start = data.index.min().date()\n",
        "end   = data.index.max().date()\n",
        "n     = data.shape[0]\n",
        "\n",
        "print(f\"Regression sample window: {start} → {end}  |  Trading days: {n}\")\n",
        "\n",
        "# ==== 4-column metrics table ====\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "from pandas_datareader import data as web\n",
        "\n",
        "FFCOLS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RF\"]\n",
        "\n",
        "# ---- A. RMSE / Corr / n ----\n",
        "def rmse_corr_from_series(series_dict):\n",
        "    rows = []\n",
        "    for t, df in series_dict.items():\n",
        "        d = df[['actual','pred']].dropna()\n",
        "        rmse = float(np.sqrt(np.mean((d['pred'] - d['actual'])**2)))\n",
        "        corr = float(d['pred'].corr(d['actual']))\n",
        "        rows.append((t, rmse, corr, int(len(d))))\n",
        "    return pd.DataFrame(rows, columns=['ticker','RMSE','Corr','n'])\n",
        "\n",
        "def rmse_corr_in_sample(data, tickers):\n",
        "    rows = []\n",
        "    for t in tickers:\n",
        "        y = (data[t] - data['RF']).dropna()\n",
        "        X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]].loc[y.index])\n",
        "        m = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":5})\n",
        "        fitted = m.fittedvalues.reindex(y.index)\n",
        "        rmse = float(np.sqrt(np.mean((y - fitted)**2)))\n",
        "        corr = float(y.corr(fitted))\n",
        "        rows.append((t, rmse, corr, int(m.nobs)))\n",
        "    return pd.DataFrame(rows, columns=['ticker','RMSE','Corr','n'])\n",
        "\n",
        "# OOS if present, else in-sample\n",
        "try:\n",
        "    metrics_rcn = rmse_corr_from_series(series)\n",
        "except NameError:\n",
        "    tickers = [c for c in data.columns if c not in FFCOLS]\n",
        "    metrics_rcn = rmse_corr_in_sample(data, tickers)\n",
        "\n",
        "# ---- B. ΔR² (best minus FF3) ----\n",
        "def dr2_from_compare_csv_or_compute():\n",
        "\n",
        "    try:\n",
        "        cmp = pd.read_csv(\"ff3_ff5_compare.csv\")\n",
        "        return cmp[[\"ticker\",\"dR2_best_minus_FF3\"]]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    ff5 = web.DataReader('F-F_Research_Data_5_Factors_2x3_Daily','famafrench')[0]\n",
        "    ff5.index = pd.to_datetime(ff5.index); ff5 = ff5[['Mkt-RF','SMB','HML','RMW','CMA']]/100.0\n",
        "    mom = web.DataReader('F-F_Momentum_Factor_Daily','famafrench')[0]\n",
        "    mom.index = pd.to_datetime(mom.index); mom = mom/100.0; mom.columns = ['Mom']\n",
        "    rf  = web.DataReader('F-F_Research_Data_Factors_Daily','famafrench')[0]\n",
        "    rf.index = pd.to_datetime(rf.index); rf = rf[['RF']]/100.0\n",
        "\n",
        "    ffX = ff5.join(mom, how='inner').join(rf, how='inner')\n",
        "    cols_ff3  = [\"Mkt-RF\",\"SMB\",\"HML\"]\n",
        "    cols_ff5  = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\"]\n",
        "    cols_car4 = [\"Mkt-RF\",\"SMB\",\"HML\",\"Mom\"]\n",
        "    cols_ff5m = [\"Mkt-RF\",\"SMB\",\"HML\",\"RMW\",\"CMA\",\"Mom\"]\n",
        "\n",
        "    dat_ff3  = rets.join(ffX[cols_ff3 + [\"RF\"]],  how=\"inner\")\n",
        "    dat_ff5  = rets.join(ffX[cols_ff5 + [\"RF\"]],  how=\"inner\")\n",
        "    dat_car4 = rets.join(ffX[cols_car4 + [\"RF\"]], how=\"inner\")\n",
        "    dat_ff5m = rets.join(ffX[cols_ff5m + [\"RF\"]], how=\"inner\")\n",
        "\n",
        "    def r2(dat, t, cols):\n",
        "        y = dat[t] - dat[\"RF\"]; X = sm.add_constant(dat[cols])\n",
        "        return sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":5}).rsquared\n",
        "\n",
        "    rows = []\n",
        "    for t in rets.columns:\n",
        "        r3  = r2(dat_ff3,  t, cols_ff3)\n",
        "        r5  = r2(dat_ff5,  t, cols_ff5)\n",
        "        r4  = r2(dat_car4, t, cols_car4)\n",
        "        r5m = r2(dat_ff5m, t, cols_ff5m)\n",
        "        rows.append((t, max(r5, r4, r5m) - r3))\n",
        "    return pd.DataFrame(rows, columns=[\"ticker\",\"dR2_best_minus_FF3\"])\n",
        "\n",
        "metrics_dr2 = dr2_from_compare_csv_or_compute()\n",
        "\n",
        "# ---- C. Merge & save ----\n",
        "out4 = (metrics_rcn.merge(metrics_dr2, on='ticker', how='left')\n",
        "                 [['ticker','RMSE','Corr','dR2_best_minus_FF3','n']])\n",
        "out4.to_csv(\"metrics_summary_4col.csv\", index=False)\n",
        "display(out4.round(4))\n",
        "print(\"Saved -> metrics_summary_4col.csv\")\n",
        "\n",
        "import numpy as np, pandas as pd, statsmodels.api as sm\n",
        "\n",
        "FFCOLS = [\"Mkt-RF\",\"SMB\",\"HML\",\"RF\"]\n",
        "\n",
        "def get_betas(ticker):\n",
        "    try:\n",
        "        b = models[ticker].params\n",
        "        return float(b['const']), float(b['Mkt-RF']), float(b['SMB']), float(b['HML'])\n",
        "    except Exception:\n",
        "        y = (data[ticker] - data[\"RF\"]).dropna()\n",
        "        X = sm.add_constant(data[[\"Mkt-RF\",\"SMB\",\"HML\"]].loc[y.index])\n",
        "        m = sm.OLS(y, X, missing=\"drop\").fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":5})\n",
        "        b = m.params\n",
        "        return float(b['const']), float(b['Mkt-RF']), float(b['SMB']), float(b['HML'])\n",
        "\n",
        "def ff3_expected_excess(alpha, bm, bs, bh, mkt_rf, smb, hml):\n",
        "    return alpha + bm*mkt_rf + bs*smb + bh*hml   # daily, decimal\n",
        "\n",
        "#  the three tickers\n",
        "names = [\"NVDA\",\"TSLA\",\"JPM\"]\n",
        "\n",
        "# --- scenarios (factor shocks are DAILY decimals)\n",
        "scenarios = [\n",
        "    #  Scenario label                        Mkt-RF    SMB     HML      Note\n",
        "    (\"Risk-on +2% market\",                   0.0200,   0.000,  0.000,  \"Broad rally: high-β names lead; mostly market-driven.\"),\n",
        "    (\"Growth-led rally\",                     0.0100,   0.000, -0.003,  \"Growth > Value (HML<0); benefits growth-tilted stocks.\"),\n",
        "    (\"Value rotation\",                       0.0050,   0.000,  0.003,  \"Value > Growth (HML>0); helps value/banks/energy.\"),\n",
        "    (\"Small-cap squeeze\",                    0.0050,   0.005,  0.000,  \"SMB>0 favors small-cap exposure; hurts large-cap tilts.\"),\n",
        "    (\"Risk-off −1.5% market\",               -0.0150,  -0.003,  0.003,  \"Flight to safety; high-β/growth lag, value defensive.\"),\n",
        "]\n",
        "\n",
        "# ---  table\n",
        "rows = []\n",
        "for label, mkt, smb, hml, note in scenarios:\n",
        "    row = {\"Scenario\": label, \"Notes\": note}\n",
        "    for t in names:\n",
        "        a,bm,bs,bh = get_betas(t)\n",
        "        r = ff3_expected_excess(a,bm,bs,bh, mkt, smb, hml)\n",
        "        row[t] = f\"{r*100:+.2f}%\"   # pretty percentage string\n",
        "    rows.append(row)\n",
        "\n",
        "scen_table = pd.DataFrame(rows, columns=[\"Scenario\",\"NVDA\",\"TSLA\",\"JPM\",\"Notes\"])\n",
        "display(scen_table)\n",
        "scen_table.to_csv(\"scenario_table_readable.csv\", index=False)\n",
        "print(\"Saved -> scenario_table_readable.csv\")\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"scenario_table_readable.csv\")\n",
        "\n",
        "df4 = df[[\"Scenario\",\"NVDA\",\"TSLA\",\"JPM\"]].copy()\n",
        "\n",
        "\n",
        "def pct_to_number(x):\n",
        "    s = str(x).strip()\n",
        "    s = re.sub(r'[%+]', '', s)  # drop % and +\n",
        "    return float(s)\n",
        "\n",
        "for c in [\"NVDA\",\"TSLA\",\"JPM\"]:\n",
        "    df4[c] = df4[c].apply(pct_to_number)\n",
        "\n",
        "\n",
        "df4.to_csv(\"scenario_table_4col.csv\", index=False)\n",
        "print(df4)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assumes `data` has daily total returns for tickers (as decimals) and RF (decimal):\n",
        "# columns like: ['NVDA','TSLA','JPM', ..., 'RF'] indexed by Date\n",
        "tickers = ['NVDA', 'TSLA', 'JPM']\n",
        "\n",
        "rf_ann = data['RF'].mean() * 252  # annualized risk-free (decimal)\n",
        "rows = []\n",
        "for t in tickers:\n",
        "    excess = (data[t] - data['RF']).dropna()\n",
        "    e_excess_ann = excess.mean() * 252          # decimal\n",
        "    e_total_ann  = e_excess_ann + rf_ann        # decimal\n",
        "    rows.append({'Ticker': t,\n",
        "                 'E_excess_ann': e_excess_ann * 100,  # percent\n",
        "                 'E_total_ann':  e_total_ann  * 100}) # percent\n",
        "\n",
        "tbl = pd.DataFrame(rows)\n",
        "tbl.to_csv('table_expected_returns.csv', index=False)\n",
        "tbl.round(2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "_df_26['beta_mkt'].plot(kind='line', figsize=(8, 4), title='beta_mkt')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EB7HhRhGMGYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title HML vs RF\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "ff3.plot(kind='scatter', x='HML', y='RF', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "yaUVlAQHsq_u"
      }
    },
    {
      "source": [
        "# @title SMB vs HML\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "ff3.plot(kind='scatter', x='SMB', y='HML', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "-xZ7w77FsecN"
      }
    }
  ]
}